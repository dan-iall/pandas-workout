{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Registration State</th>\n",
       "      <th>Vehicle Make</th>\n",
       "      <th>Violation Time</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Vehicle Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J58JKX</td>\n",
       "      <td>NJ</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>0523P</td>\n",
       "      <td>43 ST</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRE6058</td>\n",
       "      <td>PA</td>\n",
       "      <td>ME/BE</td>\n",
       "      <td>0428P</td>\n",
       "      <td>UNION ST</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444326R</td>\n",
       "      <td>NJ</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>0625A</td>\n",
       "      <td>CLERMONT AVENUE</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F728330</td>\n",
       "      <td>OH</td>\n",
       "      <td>CHEVR</td>\n",
       "      <td>1106A</td>\n",
       "      <td>DIVISION AVE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FMY9090</td>\n",
       "      <td>NY</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>1253A</td>\n",
       "      <td>GRAND ST</td>\n",
       "      <td>GREY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Plate ID Registration State Vehicle Make Violation Time      Street Name  \\\n",
       "0   J58JKX                 NJ        HONDA          0523P            43 ST   \n",
       "1  KRE6058                 PA        ME/BE          0428P         UNION ST   \n",
       "2  444326R                 NJ        LEXUS          0625A  CLERMONT AVENUE   \n",
       "3  F728330                 OH        CHEVR          1106A     DIVISION AVE   \n",
       "4  FMY9090                 NY         JEEP          1253A         GRAND ST   \n",
       "\n",
       "  Vehicle Color  \n",
       "0            BK  \n",
       "1           BLK  \n",
       "2         BLACK  \n",
       "3           NaN  \n",
       "4          GREY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../data/nyc-parking-violations-2020.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                 usecols=['Plate ID',  'Registration State',\n",
    "                        'Vehicle Make', 'Vehicle Color', 'Violation Time', 'Street Name'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ•µï¸â€â™€ï¸ Bellonda's Logic Decoder\n",
    "**The Business Goal:** Quantify the **Total Addressable Volume** of violations. This establishes our baseline \"Universe of Tickets\" before we begin filtering or cleaning.\n",
    "\n",
    "**The Syntax Anatomy:**\n",
    "* `df.index` â†’ **The Subject** (The vertical spine of the spreadsheet containing all row labels).\n",
    "* `len(...)` â†’ **The Verb** (Count the total number of items).\n",
    "* `( )` â†’ **The Scope** (Apply the count strictly to the index labels).\n",
    "\n",
    "> **ðŸ’¡ The Wisdom Check:**\n",
    "> While `len(df)` is common, using `len(df.index)` is semantically precise. It explicitly tells the reader: \"I am counting the rows (entries), not checking the data structure's depth.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12495734"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows are in the data frame when it is read into memory?\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ•µï¸â€â™€ï¸ Bellonda's Logic Decoder\n",
    "**The Business Goal:** Isolate the **\"Ironclad\" Data**. We are creating a subset of tickets where *every single field* is populated, representing the \"Safe Revenue\" (tickets that cannot be dismissed due to missing info).\n",
    "\n",
    "**The Syntax Anatomy:**\n",
    "* `df` â†’ **The Source** (Our original raw universe of tickets).\n",
    "* `.dropna()` â†’ **The Filter** (The \"Zero Tolerance\" policy).\n",
    "    * *Implicit Settings:* It defaults to `how='any'` (if 1 value is missing, drop the row) and `axis=0` (drop rows, not columns).\n",
    "* `all_good_df` â†’ **The Result** (The new DataFrame containing only perfectly complete records).\n",
    "\n",
    "> **ðŸ’¡ The Wisdom Check:**\n",
    "> `dropna()` is a blunt instrument(Sledgehammer). It discards a row even if only one minor, non-critical column is missing. Use this when data completeness is non-negotiable (e.g., financial auditing), but be careful not to throw away good data because of a missing specific detail like \"Vehicle Color\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12048375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with any missing data (i.e., a `NaN` value). How many rows remain after doing this pruning? \n",
    "all_good_df = df.dropna()\n",
    "\n",
    "len(all_good_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447359"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many parking tickets have some missing information, then?\n",
    "len(df.index) - len(all_good_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ•µï¸â€â™€ï¸ Bellonda's Logic Decoder\n",
    "**The Business Goal:** Quantify the **Financial Impact of Data Quality**. We are calculating the *Opportunity Cost*â€”the exact amount of revenue the city is losing specifically because data is missing.\n",
    "\n",
    "**The Syntax Anatomy:**\n",
    "* `f'...'` â†’ **The Formatter** (An f-string allows us to inject code logic directly into text).\n",
    "* `(len(df) - len(all_good))` â†’ **The Delta** (Total Tickets minus Perfect Tickets = The Defective Volume).\n",
    "* `* 100` â†’ **The Unit Economics** (The value of a single ticket).\n",
    "* `:,` â†’ **The Humanizer** (A format specifier that automatically adds thousands separators, e.g., turning `1000000` into `1,000,000`).\n",
    "\n",
    "> **ðŸ’¡ The Wisdom Check:**\n",
    "> This illustrates the power of Domain Knowledge. Technically, any row with a NaN is \"dirty.\" Business-wise, a NaN equates to a **$100 liability**. Always try to convert your data cleaning metrics into dollar amountsâ€”it gets stakeholders' attention immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$44,735,900'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If each parking ticket brings $100 into the city, and missing data means that the ticket can be\n",
    "# successfully contested, how much money might New York City lose as a result of such missing data?\n",
    "\n",
    "f'${(len(df.index) - len(all_good_df) ) * 100:,}'  # WOW!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ•µï¸â€â™€ï¸ Bellonda's Logic Decoder\n",
    "**The Business Goal:** Define the **Minimum Viable Record**. We are relaxing our quality control to align with business reality: a ticket is valid as long as the *legally required* fields are present, ignoring non-critical missing info (like \"Vehicle Color\").\n",
    "\n",
    "**The Syntax Anatomy:**\n",
    "* `.dropna(...)` â†’ **The Filter** (Remove rows with missing values).\n",
    "* `subset=['...']` â†’ **The Target Scope** (Restricts the filter to check *only* these specific columns).\n",
    "    * If a row has a `NaN` in 'Vehicle Color' but these 4 columns are full, it **survives**.\n",
    "* `semi_good_df` â†’ **The Recovered Dataset** (A larger set of valid tickets than our first attempt).\n",
    "\n",
    "> **ðŸ’¡ The Wisdom Check:**\n",
    "> The `subset` parameter is your most powerful tool for **Nuanced Data Cleaning**. \"Clean\" is relative. Always ask the Subject Matter Expert: implies \"Which specific fields, if missing, actually kill the deal?\" Don't clean data just to make it look pretty; clean it to make it *useful*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12431949"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's instead assume that a ticket can only be dismissed if the license plate, state, vehicle\n",
    "# make, and/or street name are all there. Remove rows that are missing one or more of these. \n",
    "# How many rows remain?\n",
    "\n",
    "semi_good_df = df.dropna(subset=['Plate ID', 'Registration State', 'Vehicle Make', 'Street Name'])\n",
    "len(semi_good_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63785"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows did we remove?\n",
    "len(df.index) - len(semi_good_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$6,378,500'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming $100/ticket, how much money would the city lose as as result of this missing data?\n",
    "\n",
    "f'${(len(df.index) - len(semi_good_df.index) ) * 100:,}'   # a bit more reasonable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12494116"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's instead assume that a ticket can only be dismissed if the license plate, state, and/or\n",
    "# street name are all there. Remove rows that are missing one or more of these. How many rows remain?\n",
    "loosest_df = df.dropna(subset=['Plate ID', 'Registration State', 'Street Name'])\n",
    "len(loosest_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1618"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows did we remove?\n",
    "len(df.index) - len(loosest_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$161,800'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming $100/ticket, how much money would the city lose as as result of this missing data?\n",
    "\n",
    "f'${(len(df.index) - len(loosest_df.index) ) * 100:,}'   # ah, much better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
